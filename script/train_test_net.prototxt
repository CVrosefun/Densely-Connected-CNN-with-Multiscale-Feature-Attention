name: "DenseAttentionNet"
layer {
  name: "data"
  type: "TextData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  text_data_param {
    label_source: "/ssd/ijcai18/data/agnews/train_label.txt"
    data_source: "/ssd/ijcai18/data/agnews/train_data.txt"
    dict_source: "/ssd/ijcai18/data/agnews/local_dic_index.txt"
    batch_size: 64
    channel: 1
    num_words: 200
    crop_height: 100
    crop_width: 300
  }
}
layer {
  name: "data"
  type: "TextData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  text_data_param {
    label_source: "/ssd/ijcai18/data/agnews/test_label.txt"
    data_source: "/ssd/ijcai18/data/agnews/test_data.txt"
    dict_source: "/ssd/ijcai18/data/agnews/local_dic_index.txt"
    batch_size: 80
    channel: 1
    num_words: 100
    crop_height: 100
    crop_width: 300
    shuffle: 0
  }
}
#----Transform Feature Dimension----
layer {
  name: "trans_layer_conv0"
  bottom: "data"
  top: "trans_layer_conv0"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 1
    kernel_w: 300
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "trans_layer_bn0"
  bottom: "trans_layer_conv0"
  top: "trans_layer_bn0"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "trans_layer_relu0"
  bottom: "trans_layer_bn0"
  top: "trans_layer_bn0"
  type: "ReLU"
}
layer {
  name: "trans_layer_conv1"
  bottom: "trans_layer_bn0"
  top: "trans_layer_conv1"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 1
    kernel_w: 1
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "trans_layer_bn1"
  bottom: "trans_layer_conv1"
  top: "trans_layer_bn1"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "trans_layer_relu1"
  bottom: "trans_layer_bn1"
  top: "trans_layer_bn1"
  type: "ReLU"
}
layer {
  name: "trans_layer_conv2"
  bottom: "trans_layer_bn1"
  top: "trans_layer_conv2"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 1
    kernel_w: 1
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "trans_layer_bn2"
  bottom: "trans_layer_conv2"
  top: "trans_layer_bn2"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "trans_layer_relu2"
  bottom: "trans_layer_bn2"
  top: "trans_layer_bn2"
  type: "ReLU"
}
#----Dense CNN----
layer {
  name: "dense_layer_conv0"
  bottom: "trans_layer_bn2"
  top: "dense_layer_conv0"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 3
    kernel_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_concat0"
  bottom: "dense_layer_conv0"
  bottom: "trans_layer_conv0"
  bottom: "trans_layer_conv1"
  bottom: "trans_layer_conv2"
  top: "dense_layer_concat0"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dense_layer_bn0"
  bottom: "dense_layer_concat0"
  top: "dense_layer_bn0"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "dense_layer_relu0"
  bottom: "dense_layer_bn0"
  top: "dense_layer_bn0"
  type: "ReLU"
}
layer {
  name: "dense_layer_pool0"
  bottom: "dense_layer_bn0"
  top: "dense_layer_pool0"
  type: "Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 3
    kernel_w: 1
    stride_h: 2
    stride_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_conv1"
  bottom: "dense_layer_pool0"
  top: "dense_layer_conv1"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 3
    kernel_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_concat1"
  bottom: "dense_layer_conv1"
  bottom: "dense_layer_pool0"
  top: "dense_layer_concat1"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dense_layer_bn1"
  bottom: "dense_layer_concat1"
  top: "dense_layer_bn1"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "dense_layer_relu1"
  bottom: "dense_layer_bn1"
  top: "dense_layer_bn1"
  type: "ReLU"
}
layer {
  name: "dense_layer_pool1"
  bottom: "dense_layer_bn1"
  top: "dense_layer_pool1"
  type: "Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 3
    kernel_w: 1
    stride_h: 2
    stride_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_conv2"
  bottom: "dense_layer_pool1"
  top: "dense_layer_conv2"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 3
    kernel_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_concat2"
  bottom: "dense_layer_conv2"
  bottom: "dense_layer_pool1"
  top: "dense_layer_concat2"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dense_layer_bn2"
  bottom: "dense_layer_concat2"
  top: "dense_layer_bn2"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "dense_layer_relu2"
  bottom: "dense_layer_bn2"
  top: "dense_layer_bn2"
  type: "ReLU"
}
layer {
  name: "dense_layer_pool2"
  bottom: "dense_layer_bn2"
  top: "dense_layer_pool2"
  type: "Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 3
    kernel_w: 1
    stride_h: 2
    stride_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_conv3"
  bottom: "dense_layer_pool2"
  top: "dense_layer_conv3"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 3
    kernel_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_concat3"
  bottom: "dense_layer_conv3"
  bottom: "dense_layer_pool2"
  top: "dense_layer_concat3"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dense_layer_bn3"
  bottom: "dense_layer_concat3"
  top: "dense_layer_bn3"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "dense_layer_relu3"
  bottom: "dense_layer_bn3"
  top: "dense_layer_bn3"
  type: "ReLU"
}
layer {
  name: "dense_layer_pool3"
  bottom: "dense_layer_bn3"
  top: "dense_layer_pool3"
  type: "Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 3
    kernel_w: 1
    stride_h: 2
    stride_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_conv4"
  bottom: "dense_layer_pool3"
  top: "dense_layer_conv4"
  type: "Convolution"
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    kernel_h: 3
    kernel_w: 1
    pad_h: 1
    pad_w: 0
  }
}
layer {
  name: "dense_layer_concat4"
  bottom: "dense_layer_conv4"
  bottom: "dense_layer_pool3"
  top: "dense_layer_concat4"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "dense_layer_bn4"
  bottom: "dense_layer_concat4"
  top: "dense_layer_bn4"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "dense_layer_relu4"
  bottom: "dense_layer_bn4"
  top: "dense_layer_bn4"
  type: "ReLU"
}
#----Multi-scale Feature Attention----
layer {
  name: "attention_layer_conv0"
  bottom: "dense_layer_bn4"
  top: "attention_layer_conv0"
  type: "Convolution"
  convolution_param {
    num_output: 512
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 8
    kernel_h: 1
    kernel_w: 1
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "attention_layer_bn0"
  bottom: "attention_layer_conv0"
  top: "attention_layer_bn0"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "attention_layer_relu0"
  bottom: "attention_layer_bn0"
  top: "attention_layer_bn0"
  type: "ReLU"
}
layer {
  name: "attention_layer_conv1"
  bottom: "attention_layer_bn0"
  top: "attention_layer_conv1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.058925565
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 8
    kernel_h: 1
    kernel_w: 1
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "attention_layer_bn1"
  bottom: "attention_layer_conv1"
  top: "attention_layer_bn1"
  type: "BatchNorm"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "attention_layer_relu1"
  bottom: "attention_layer_bn1"
  top: "attention_layer_bn1"
  type: "ReLU"
}
layer {
  name: "attention_scale_slice"
  bottom: "attention_layer_bn1"
  top: "attention_scale0"
  top: "attention_scale1"
  top: "attention_scale2"
  top: "attention_scale3"
  top: "attention_scale4"
  top: "attention_scale5"
  top: "attention_scale6"
  top: "attention_scale7"
  type: "Slice"
  slice_param {
    axis: 1
    slice_point: 64
    slice_point: 128
    slice_point: 192
    slice_point: 256
    slice_point: 320
    slice_point: 384
    slice_point: 448
    }
}
layer {
  name: "attention_permute0"
  bottom: "attention_scale0"
  top: "attention_permute0"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction0"
  bottom: "attention_permute0"
  top: "attention_reduction0"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute1"
  bottom: "attention_scale1"
  top: "attention_permute1"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction1"
  bottom: "attention_permute1"
  top: "attention_reduction1"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute2"
  bottom: "attention_scale2"
  top: "attention_permute2"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction2"
  bottom: "attention_permute2"
  top: "attention_reduction2"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute3"
  bottom: "attention_scale3"
  top: "attention_permute3"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction3"
  bottom: "attention_permute3"
  top: "attention_reduction3"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute4"
  bottom: "attention_scale4"
  top: "attention_permute4"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction4"
  bottom: "attention_permute4"
  top: "attention_reduction4"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute5"
  bottom: "attention_scale5"
  top: "attention_permute5"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction5"
  bottom: "attention_permute5"
  top: "attention_reduction5"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute6"
  bottom: "attention_scale6"
  top: "attention_permute6"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction6"
  bottom: "attention_permute6"
  top: "attention_reduction6"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_permute7"
  bottom: "attention_scale7"
  top: "attention_permute7"
  type: "Permute"
  permute_param {
      order: 0
      order: 3
      order: 2
      order: 1
  }
}
layer {
  name: "attention_reduction7"
  bottom: "attention_permute7"
  top: "attention_reduction7"
  type: "Reduction"
  reduction_param {
    axis: 3
    }
}
layer {
  name: "attention_scale_concat"
  bottom: "attention_reduction0"
  bottom: "attention_reduction1"
  bottom: "attention_reduction2"
  bottom: "attention_reduction3"
  bottom: "attention_reduction4"
  bottom: "attention_reduction5"
  bottom: "attention_reduction6"
  bottom: "attention_reduction7"
  top: "attention_scale_concat"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "attention_height_slice"
  bottom: "attention_scale_concat"
  top: "attention_height0"
  top: "attention_height1"
  top: "attention_height2"
  top: "attention_height3"
  top: "attention_height4"
  top: "attention_height5"
  top: "attention_height6"
  top: "attention_height7"
  type: "Slice"
  slice_param {
    axis: 2
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    }
}
layer {
  name: "attention_height_fc1_0"
  type: "InnerProduct"
  bottom: "attention_height0"
  top: "attention_height_fc1_0"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_0"
  type: "InnerProduct"
  bottom: "attention_height_fc1_0"
  top: "attention_height_fc2_0"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_0"
  type: "InnerProduct"
  bottom: "attention_height_fc2_0"
  top: "attention_height_fc3_0"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape0"
  bottom: "attention_height_fc3_0"
  top: "attention_height_reshape0"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_1"
  type: "InnerProduct"
  bottom: "attention_height1"
  top: "attention_height_fc1_1"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_1"
  type: "InnerProduct"
  bottom: "attention_height_fc1_1"
  top: "attention_height_fc2_1"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_1"
  type: "InnerProduct"
  bottom: "attention_height_fc2_1"
  top: "attention_height_fc3_1"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape1"
  bottom: "attention_height_fc3_1"
  top: "attention_height_reshape1"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_2"
  type: "InnerProduct"
  bottom: "attention_height2"
  top: "attention_height_fc1_2"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_2"
  type: "InnerProduct"
  bottom: "attention_height_fc1_2"
  top: "attention_height_fc2_2"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_2"
  type: "InnerProduct"
  bottom: "attention_height_fc2_2"
  top: "attention_height_fc3_2"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape2"
  bottom: "attention_height_fc3_2"
  top: "attention_height_reshape2"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_3"
  type: "InnerProduct"
  bottom: "attention_height3"
  top: "attention_height_fc1_3"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_3"
  type: "InnerProduct"
  bottom: "attention_height_fc1_3"
  top: "attention_height_fc2_3"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_3"
  type: "InnerProduct"
  bottom: "attention_height_fc2_3"
  top: "attention_height_fc3_3"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape3"
  bottom: "attention_height_fc3_3"
  top: "attention_height_reshape3"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_4"
  type: "InnerProduct"
  bottom: "attention_height4"
  top: "attention_height_fc1_4"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_4"
  type: "InnerProduct"
  bottom: "attention_height_fc1_4"
  top: "attention_height_fc2_4"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_4"
  type: "InnerProduct"
  bottom: "attention_height_fc2_4"
  top: "attention_height_fc3_4"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape4"
  bottom: "attention_height_fc3_4"
  top: "attention_height_reshape4"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_5"
  type: "InnerProduct"
  bottom: "attention_height5"
  top: "attention_height_fc1_5"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_5"
  type: "InnerProduct"
  bottom: "attention_height_fc1_5"
  top: "attention_height_fc2_5"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_5"
  type: "InnerProduct"
  bottom: "attention_height_fc2_5"
  top: "attention_height_fc3_5"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape5"
  bottom: "attention_height_fc3_5"
  top: "attention_height_reshape5"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_6"
  type: "InnerProduct"
  bottom: "attention_height6"
  top: "attention_height_fc1_6"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_6"
  type: "InnerProduct"
  bottom: "attention_height_fc1_6"
  top: "attention_height_fc2_6"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_6"
  type: "InnerProduct"
  bottom: "attention_height_fc2_6"
  top: "attention_height_fc3_6"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape6"
  bottom: "attention_height_fc3_6"
  top: "attention_height_reshape6"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_fc1_7"
  type: "InnerProduct"
  bottom: "attention_height7"
  top: "attention_height_fc1_7"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc2_7"
  type: "InnerProduct"
  bottom: "attention_height_fc1_7"
  top: "attention_height_fc2_7"
  inner_product_param {
     num_output: 32
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_fc3_7"
  type: "InnerProduct"
  bottom: "attention_height_fc2_7"
  top: "attention_height_fc3_7"
  inner_product_param {
     num_output: 8
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "attention_height_reshape7"
  bottom: "attention_height_fc3_7"
  top: "attention_height_reshape7"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "attention_height_concat"
  bottom: "attention_height_reshape0"
  bottom: "attention_height_reshape1"
  bottom: "attention_height_reshape2"
  bottom: "attention_height_reshape3"
  bottom: "attention_height_reshape4"
  bottom: "attention_height_reshape5"
  bottom: "attention_height_reshape6"
  bottom: "attention_height_reshape7"
  top: "attention_height_concat"
  type: "Concat"
  concat_param {
    axis: 2
  }
}
layer {
  name: "attention_weight"
  type: "Softmax"
  bottom: "attention_height_concat"
  top: "attention_weight"
}
layer {
  name: "attention_weight_slice"
  bottom: "attention_weight"
  top: "attention_weight_slice0"
  top: "attention_weight_slice1"
  top: "attention_weight_slice2"
  top: "attention_weight_slice3"
  top: "attention_weight_slice4"
  top: "attention_weight_slice5"
  top: "attention_weight_slice6"
  top: "attention_weight_slice7"
  type: "Slice"
  slice_param {
    axis: 1
    slice_point: 1
    slice_point: 2
    slice_point: 3
    slice_point: 4
    slice_point: 5
    slice_point: 6
    slice_point: 7
    }
}
layer {
  name: "attention_weight_tile0"
  bottom: "attention_weight_slice0"
  top: "attention_weight_tile0"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight0"
  bottom: "attention_scale0"
  bottom: "attention_weight_tile0"
  top: "attention_reweight0"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile1"
  bottom: "attention_weight_slice1"
  top: "attention_weight_tile1"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight1"
  bottom: "attention_scale1"
  bottom: "attention_weight_tile1"
  top: "attention_reweight1"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile2"
  bottom: "attention_weight_slice2"
  top: "attention_weight_tile2"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight2"
  bottom: "attention_scale2"
  bottom: "attention_weight_tile2"
  top: "attention_reweight2"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile3"
  bottom: "attention_weight_slice3"
  top: "attention_weight_tile3"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight3"
  bottom: "attention_scale3"
  bottom: "attention_weight_tile3"
  top: "attention_reweight3"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile4"
  bottom: "attention_weight_slice4"
  top: "attention_weight_tile4"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight4"
  bottom: "attention_scale4"
  bottom: "attention_weight_tile4"
  top: "attention_reweight4"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile5"
  bottom: "attention_weight_slice5"
  top: "attention_weight_tile5"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight5"
  bottom: "attention_scale5"
  bottom: "attention_weight_tile5"
  top: "attention_reweight5"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile6"
  bottom: "attention_weight_slice6"
  top: "attention_weight_tile6"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight6"
  bottom: "attention_scale6"
  bottom: "attention_weight_tile6"
  top: "attention_reweight6"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_weight_tile7"
  bottom: "attention_weight_slice7"
  top: "attention_weight_tile7"
  type: "Tile"
  tile_param {
    axis: 1
    tiles: 64
  }
}
layer {
  name: "attention_reweight7"
  bottom: "attention_scale7"
  bottom: "attention_weight_tile7"
  top: "attention_reweight7"
  type: "Eltwise"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attention_reweight_sum"
  bottom: "attention_reweight0"
  bottom: "attention_reweight1"
  bottom: "attention_reweight2"
  bottom: "attention_reweight3"
  bottom: "attention_reweight4"
  bottom: "attention_reweight5"
  bottom: "attention_reweight6"
  bottom: "attention_reweight7"
  top: "attention_reweight_sum"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "attention_reweight_flatten"
  bottom: "attention_reweight_sum"
  top: "attention_reweight_flatten"
  type: "Flatten"
}
layer {
  name: "attention_reweight_dropout"
  bottom: "attention_reweight_flatten"
  top: "attention_reweight_dropout"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.700000
  }
}
layer {
  name: "classification_fc1"
  type: "InnerProduct"
  bottom: "attention_reweight_dropout"
  top: "classification_fc1"
  inner_product_param {
     num_output: 64
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "classification_dropout"
  bottom: "classification_fc1"
  top: "classification_dropout"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.700000
  }
}
layer {
  name: "classification_fc2"
  type: "InnerProduct"
  bottom: "classification_dropout"
  top: "classification_fc2"
  param {
    lr_mult: 10
    decay_mult: 2
  }
  param {
    lr_mult: 10
    decay_mult: 2
  }
  inner_product_param {
     num_output: 4
     weight_filler {
       type: "gaussian"
       std: 0.001
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "classification_loss"
  type: "SoftmaxWithLoss"
  bottom: "classification_fc2"
  bottom: "label"
  top: "classification_loss"
  loss_weight: 1.000000
}
layer {
  name: "classification_accuracy"
  type: "Accuracy"
  bottom: "classification_fc2"
  bottom: "label"
  top: "classification_accuracy"
}
